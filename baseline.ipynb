{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "284f2bc0",
   "metadata": {},
   "source": [
    "# Baseline Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "599fe221-aea7-4161-9a05-507960426cc7",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9f14069-1756-49cc-a63f-8665deab26fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-30T11:57:46.028757Z",
     "iopub.status.busy": "2022-08-30T11:57:46.027647Z",
     "iopub.status.idle": "2022-08-30T11:57:48.841005Z",
     "shell.execute_reply": "2022-08-30T11:57:48.839177Z",
     "shell.execute_reply.started": "2022-08-30T11:57:46.028580Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c609a58a-dee2-4dc2-9a50-48ee07db5d16",
   "metadata": {},
   "source": [
    "## CONFIG"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d683ab85-ae86-4529-bbda-2230848407ba",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Data Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "310bb5c2-e66e-4635-a354-7da873df89f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-30T11:58:03.267504Z",
     "iopub.status.busy": "2022-08-30T11:58:03.265981Z",
     "iopub.status.idle": "2022-08-30T11:58:03.279293Z",
     "shell.execute_reply": "2022-08-30T11:58:03.277393Z",
     "shell.execute_reply.started": "2022-08-30T11:58:03.267398Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATA_DIR = '/workspace/Competition/PSG/data/final'\n",
    "label_dir = os.path.join(DATA_DIR, 'train_labels.csv')\n",
    "train_dir = os.path.join(DATA_DIR, 'train')\n",
    "test_dir = os.path.join(DATA_DIR, 'test')\n",
    "result_dir = os.path.join('/workspace/Competition/PSG/data/results')\n",
    "norm_dir = os.path.join(DATA_DIR, 'norm.npy')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b4f198f3-bc73-4d67-b3b1-4ae963fd052e",
   "metadata": {},
   "source": [
    "#### Set Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1488db4-7545-44f1-b529-feed58d7d74b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-30T11:58:06.596913Z",
     "iopub.status.busy": "2022-08-30T11:58:06.595688Z",
     "iopub.status.idle": "2022-08-30T11:58:06.611400Z",
     "shell.execute_reply": "2022-08-30T11:58:06.609318Z",
     "shell.execute_reply.started": "2022-08-30T11:58:06.596834Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "RANDOM_SEED = 2022\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(RANDOM_SEED)\n",
    "random.seed(RANDOM_SEED)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4e1fc70a-2695-4285-8764-9c57bcb85cd2",
   "metadata": {},
   "source": [
    "#### Set Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e6c97f6-c71a-4a23-8756-814eb7c10dcc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-30T11:58:07.329775Z",
     "iopub.status.busy": "2022-08-30T11:58:07.328743Z",
     "iopub.status.idle": "2022-08-30T11:58:07.381119Z",
     "shell.execute_reply": "2022-08-30T11:58:07.379433Z",
     "shell.execute_reply.started": "2022-08-30T11:58:07.329705Z"
    }
   },
   "outputs": [],
   "source": [
    "# GPU config\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\"\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "24834c28-ed64-495b-b523-62bbc1178a88",
   "metadata": {},
   "source": [
    "#### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ec1b73fa-54c7-4266-8cea-8516ca838bac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-30T11:58:08.229719Z",
     "iopub.status.busy": "2022-08-30T11:58:08.228826Z",
     "iopub.status.idle": "2022-08-30T11:58:08.237702Z",
     "shell.execute_reply": "2022-08-30T11:58:08.235943Z",
     "shell.execute_reply.started": "2022-08-30T11:58:08.229655Z"
    }
   },
   "outputs": [],
   "source": [
    "EPOCHS = 20\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 0.0003\n",
    "EARLY_STOPPING_PATIENCE = 10"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "498eb22e-e2db-4d11-b3d4-1bf8918b749a",
   "metadata": {},
   "source": [
    "## Define Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5a44426d-b2a4-4cb4-b321-7e69d8815c6f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-30T11:58:09.177179Z",
     "iopub.status.busy": "2022-08-30T11:58:09.176273Z",
     "iopub.status.idle": "2022-08-30T11:58:09.195215Z",
     "shell.execute_reply": "2022-08-30T11:58:09.193881Z",
     "shell.execute_reply.started": "2022-08-30T11:58:09.177112Z"
    }
   },
   "outputs": [],
   "source": [
    "class EEG_Single_Dataset(Dataset):\n",
    "    def __init__(self, datapath, labeldf, normpath):\n",
    "        self.df = labeldf\n",
    "        self.label_encoding = {'W':0, 'N1':1, 'N2':2, 'N3':3, 'R':4}\n",
    "        self.data_path = datapath\n",
    "        self.file_ids = self.df['rec_id']\n",
    "        self.labels = self.df['stage']\n",
    "        self.normparams = np.load(normpath).astype('float32')\n",
    "        self.mean = self.normparams[0]\n",
    "        self.std = self.normparams[1]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.file_ids)\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        npypath = os.path.join(self.data_path, self.file_ids[index])\n",
    "        x = torch.from_numpy(np.load(npypath).astype('float32'))\n",
    "        x = (x-self.mean)/self.std\n",
    "        subx = x[-30*128:].view(1,-1)\n",
    "        label = self.labels[index]\n",
    "        y = self.label_encoding[label]\n",
    "        \n",
    "        return subx,y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3f405461-717f-4438-8cb6-164e6859ba5c",
   "metadata": {},
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef14efb7-0c1a-49a5-88af-9acf791ead7a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-30T11:58:11.658433Z",
     "iopub.status.busy": "2022-08-30T11:58:11.656519Z",
     "iopub.status.idle": "2022-08-30T11:58:11.682812Z",
     "shell.execute_reply": "2022-08-30T11:58:11.681304Z",
     "shell.execute_reply.started": "2022-08-30T11:58:11.658357Z"
    }
   },
   "outputs": [],
   "source": [
    "class DOUBLE_CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DOUBLE_CNN, self).__init__()\n",
    "        \n",
    "        self.small_cnn = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=1, out_channels=64, kernel_size=int(128/2), stride = int(128/16)),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=8, stride=8),\n",
    "            nn.Dropout(p=0.3),\n",
    "            nn.Conv1d(in_channels=64, out_channels=128, kernel_size=4),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(in_channels=128, out_channels=128, kernel_size=4),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(in_channels=128, out_channels=128, kernel_size=4),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=4, stride=4),\n",
    "        )\n",
    "\n",
    "        self.large_cnn = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=1, out_channels=64, kernel_size=128*4, stride=int(128/2)),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=4, stride=4),\n",
    "            nn.Dropout(p=0.3),\n",
    "            nn.Conv1d(in_channels = 64, out_channels=128, kernel_size=3),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(in_channels = 128, out_channels = 128, kernel_size=3),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear((12+4)*128,1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024,128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128,64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64,5)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        xs = self.small_cnn(x)\n",
    "        xl = self.large_cnn(x)\n",
    "        xs = xs.flatten(1,2)\n",
    "        xl = xl.flatten(1,2)\n",
    "        xcat = torch.cat((xs,xl),1)\n",
    "        out = self.fc(xcat)\n",
    "        return out"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fea6095b-f7d4-4b9f-9539-ffd004bbe806",
   "metadata": {},
   "source": [
    "## Utils\n",
    "#### EarlyStopper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26811310-d914-45cf-88ec-2412926ab4b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-30T11:58:13.565183Z",
     "iopub.status.busy": "2022-08-30T11:58:13.564416Z",
     "iopub.status.idle": "2022-08-30T11:58:13.574854Z",
     "shell.execute_reply": "2022-08-30T11:58:13.573764Z",
     "shell.execute_reply.started": "2022-08-30T11:58:13.565134Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LossEarlyStopper():\n",
    "    def __init__(self, patience: int)-> None:\n",
    "        self.patience = patience\n",
    "        self.patience_counter = 0\n",
    "        self.min_loss = np.Inf\n",
    "        self.stop = False\n",
    "        self.savel_model = False\n",
    "        \n",
    "    def check_early_stopping(self, loss: float)-> None:\n",
    "        if loss > self.min_loss:\n",
    "            self.patience_counter +=1\n",
    "            msg = f\"Early stopping counter {self.patience_counter}/{self.patience}\"\n",
    "            \n",
    "            if self.patience_counter == self.patience:\n",
    "                self.stop=True\n",
    "            \n",
    "        else:\n",
    "            self.patience_counter = 0\n",
    "            self.save_model = True\n",
    "            msg = f\"Validation loss decreased {self.min_loss} - > {loss}\"\n",
    "            self.min_loss = loss\n",
    "        print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d42730-3920-4742-a2cf-e735a2659839",
   "metadata": {},
   "source": [
    "#### Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0592fe02-03da-4f19-bedd-b35a3f4a55c4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-30T11:58:16.037734Z",
     "iopub.status.busy": "2022-08-30T11:58:16.036219Z",
     "iopub.status.idle": "2022-08-30T11:58:16.062342Z",
     "shell.execute_reply": "2022-08-30T11:58:16.060998Z",
     "shell.execute_reply.started": "2022-08-30T11:58:16.037652Z"
    }
   },
   "outputs": [],
   "source": [
    "class Trainer():\n",
    "    def __init__(self, model, optimizer, loss, metrics, device):\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.loss = loss\n",
    "        self.metric_fn = metrics\n",
    "        self.device = device\n",
    "        \n",
    "    def train_epoch(self, dataloader, epoch_index):\n",
    "        self.model.train()\n",
    "        train_total_loss = 0\n",
    "        target_list = []\n",
    "        pred_list = []\n",
    "        \n",
    "        for batch_index, (x,y) in enumerate(dataloader):\n",
    "            x,y = x.to(self.device), y.to(self.device)\n",
    "            y_pred = model(x)\n",
    "            loss = self.loss(y_pred,y)\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            \n",
    "            train_total_loss += loss.item()\n",
    "            pred_list.extend(y_pred.argmax(dim=1).cpu().tolist())\n",
    "            target_list.extend(y.cpu().tolist())\n",
    "        self.train_mean_loss = train_total_loss / (batch_index+1)\n",
    "        train_score, f1 = self.metric_fn(y_pred=pred_list, y_answer=target_list)\n",
    "        msg = f\"Epoch {epoch_index}, Train loss: {self.train_mean_loss}, Acc:{train_score}, F1-Macro: {f1}\"\n",
    "        print(msg)\n",
    "    \n",
    "    def validate_epoch(self, dataloader, epoch_index):\n",
    "        val_total_loss = 0\n",
    "        target_list = []\n",
    "        pred_list = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch_index, (x, y) in enumerate(dataloader):\n",
    "                x = x.to(self.device)\n",
    "                y = y.to(self.device)\n",
    "                y_pred = self.model(x)\n",
    "                loss = self.loss(y_pred, y)\n",
    "                \n",
    "                val_total_loss += loss.item()\n",
    "                target_list.extend(y.cpu().tolist())\n",
    "                pred_list.extend(y_pred.argmax(dim=1).cpu().tolist())\n",
    "        self.val_mean_loss = val_total_loss / (batch_index+1)\n",
    "        val_score, f1 = self.metric_fn(y_pred = pred_list, y_answer = target_list)\n",
    "        msg = f\"Epoch {epoch_index}, Val loss: {self.val_mean_loss}, Acc:{val_score}, F1-Macro: {f1}\"\n",
    "        print(msg)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "688a15fb-6376-42e1-90e4-39871ae239a1",
   "metadata": {},
   "source": [
    "#### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ddb9601-fbdd-4ccc-89cc-ffa51e6ec4f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-30T11:58:18.129221Z",
     "iopub.status.busy": "2022-08-30T11:58:18.127995Z",
     "iopub.status.idle": "2022-08-30T11:58:18.140612Z",
     "shell.execute_reply": "2022-08-30T11:58:18.138294Z",
     "shell.execute_reply.started": "2022-08-30T11:58:18.129140Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_metric_fn(y_pred, y_answer):\n",
    "    assert len(y_pred) == len(y_answer), 'The size of prediction and answer are not the same.'\n",
    "    accuracy = accuracy_score(y_answer, y_pred)\n",
    "    f1 = f1_score(y_answer, y_pred, average='macro')\n",
    "    return accuracy, f1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c276a244-113d-475c-9102-2be0f313d2ed",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7b615cbe-a2a3-4f90-91ee-5f552bec9c92",
   "metadata": {},
   "source": [
    "#### Set Dataset & Dataloader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "95431737-bba8-4f11-ad93-1858738d123d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-30T11:58:20.226522Z",
     "iopub.status.busy": "2022-08-30T11:58:20.225566Z",
     "iopub.status.idle": "2022-08-30T11:58:20.268270Z",
     "shell.execute_reply": "2022-08-30T11:58:20.267387Z",
     "shell.execute_reply.started": "2022-08-30T11:58:20.226444Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'BATCH_SIZE' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/workspace/Competition/PSG/baseline.ipynb Cell 25\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bpsg/workspace/Competition/PSG/baseline.ipynb#X33sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m train_dataset \u001b[39m=\u001b[39m EEG_Single_Dataset(datapath\u001b[39m=\u001b[39mtrain_dir, labeldf\u001b[39m=\u001b[39mtraindf, normpath\u001b[39m=\u001b[39mnorm_dir)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bpsg/workspace/Competition/PSG/baseline.ipynb#X33sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m val_dataset \u001b[39m=\u001b[39m EEG_Single_Dataset(datapath\u001b[39m=\u001b[39mtrain_dir, labeldf\u001b[39m=\u001b[39mvaldf, normpath\u001b[39m=\u001b[39mnorm_dir)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bpsg/workspace/Competition/PSG/baseline.ipynb#X33sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m train_loader \u001b[39m=\u001b[39m DataLoader(train_dataset, batch_size\u001b[39m=\u001b[39mBATCH_SIZE, shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bpsg/workspace/Competition/PSG/baseline.ipynb#X33sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m val_loader \u001b[39m=\u001b[39m DataLoader(val_dataset, batch_size\u001b[39m=\u001b[39mBATCH_SIZE, shuffle\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bpsg/workspace/Competition/PSG/baseline.ipynb#X33sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mTrain set samples: \u001b[39m\u001b[39m'\u001b[39m, \u001b[39mlen\u001b[39m(train_dataset), \u001b[39m'\u001b[39m\u001b[39mVal set samples: \u001b[39m\u001b[39m'\u001b[39m, \u001b[39mlen\u001b[39m(val_dataset))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'BATCH_SIZE' is not defined"
     ]
    }
   ],
   "source": [
    "# Load label dataframe\n",
    "entiredf = pd.read_csv(label_dir)\n",
    "traindf, valdf = train_test_split(entiredf, test_size=0.2)\n",
    "traindf = traindf.reset_index(drop=True)\n",
    "valdf = valdf.reset_index(drop=True)\n",
    "\n",
    "\n",
    "train_dataset = EEG_Single_Dataset(datapath=train_dir, labeldf=traindf, normpath=norm_dir)\n",
    "val_dataset = EEG_Single_Dataset(datapath=train_dir, labeldf=valdf, normpath=norm_dir)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "print('Train set samples: ', len(train_dataset), 'Val set samples: ', len(val_dataset))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e0dba7ae-d65f-46b1-87d5-068ce5c3308e",
   "metadata": {},
   "source": [
    "#### Set Model and trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef07a0b7-e56e-48eb-82a7-4b2c7bc5df45",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-30T11:58:22.329575Z",
     "iopub.status.busy": "2022-08-30T11:58:22.327852Z",
     "iopub.status.idle": "2022-08-30T11:58:33.409108Z",
     "shell.execute_reply": "2022-08-30T11:58:33.405007Z",
     "shell.execute_reply.started": "2022-08-30T11:58:22.329490Z"
    }
   },
   "outputs": [],
   "source": [
    "model = DOUBLE_CNN().to(DEVICE)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "early_stopper = LossEarlyStopper(patience=EARLY_STOPPING_PATIENCE)\n",
    "metrics = get_metric_fn\n",
    "\n",
    "trainer = Trainer(model, optimizer, loss_fn, get_metric_fn, DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ab397dfb-87d8-4b8b-a34e-b5a060d8c39c",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2022-08-30T11:58:33.416541Z",
     "iopub.status.busy": "2022-08-30T11:58:33.415500Z",
     "iopub.status.idle": "2022-08-30T11:58:33.439887Z",
     "shell.execute_reply": "2022-08-30T11:58:33.438677Z",
     "shell.execute_reply.started": "2022-08-30T11:58:33.416466Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DOUBLE_CNN(\n",
       "  (small_cnn): Sequential(\n",
       "    (0): Conv1d(1, 64, kernel_size=(64,), stride=(8,))\n",
       "    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool1d(kernel_size=8, stride=8, padding=0, dilation=1, ceil_mode=False)\n",
       "    (4): Dropout(p=0.3, inplace=False)\n",
       "    (5): Conv1d(64, 128, kernel_size=(4,), stride=(1,))\n",
       "    (6): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): ReLU()\n",
       "    (8): Conv1d(128, 128, kernel_size=(4,), stride=(1,))\n",
       "    (9): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (10): ReLU()\n",
       "    (11): Conv1d(128, 128, kernel_size=(4,), stride=(1,))\n",
       "    (12): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (13): ReLU()\n",
       "    (14): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (large_cnn): Sequential(\n",
       "    (0): Conv1d(1, 64, kernel_size=(512,), stride=(64,))\n",
       "    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "    (4): Dropout(p=0.3, inplace=False)\n",
       "    (5): Conv1d(64, 128, kernel_size=(3,), stride=(1,))\n",
       "    (6): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): ReLU()\n",
       "    (8): Conv1d(128, 128, kernel_size=(3,), stride=(1,))\n",
       "    (9): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (10): ReLU()\n",
       "    (11): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=64, out_features=5, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ee52b13c-38ca-427f-a0b2-537df07dce72",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aa9faef9-ead3-4bfa-9534-23d920050abd",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2022-08-30T11:58:37.398898Z",
     "iopub.status.busy": "2022-08-30T11:58:37.397933Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Train loss: 1.002196481221617, Acc:0.5887037189064938, F1-Macro: 0.4200351549566871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1/20 [00:13<04:22, 13.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Val loss: 0.9083360452204943, Acc:0.639527248850952, F1-Macro: 0.5119867344475857\n",
      "Validation loss decreased inf - > 0.9083360452204943\n",
      "Epoch 1, Train loss: 0.862658102994203, Acc:0.6543797717757163, F1-Macro: 0.5123175219949341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 2/20 [00:27<04:08, 13.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Val loss: 0.8320806616296371, Acc:0.6680892974392646, F1-Macro: 0.5251614337258814\n",
      "Validation loss decreased 0.9083360452204943 - > 0.8320806616296371\n",
      "Epoch 2, Train loss: 0.8028361478189784, Acc:0.6889417945981446, F1-Macro: 0.546197073313224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 3/20 [00:41<03:54, 13.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Val loss: 0.7837761209035913, Acc:0.7032173342087984, F1-Macro: 0.5588789763820738\n",
      "Validation loss decreased 0.8320806616296371 - > 0.7837761209035913\n",
      "Epoch 3, Train loss: 0.7640197228571874, Acc:0.7117642229701995, F1-Macro: 0.5688389049384436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 4/20 [00:54<03:38, 13.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Val loss: 0.834229551255703, Acc:0.6723571897570584, F1-Macro: 0.5175885512263101\n",
      "Early stopping counter 1/10\n",
      "Epoch 4, Train loss: 0.7274075289723754, Acc:0.7268697151301207, F1-Macro: 0.5806826174322414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 5/20 [01:08<03:25, 13.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Val loss: 0.7388613211611906, Acc:0.7242284963887065, F1-Macro: 0.5788078236168671\n",
      "Validation loss decreased 0.7837761209035913 - > 0.7388613211611906\n",
      "Epoch 5, Train loss: 0.6937615220628073, Acc:0.7413184467613496, F1-Macro: 0.5940317052540717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 6/20 [01:22<03:12, 13.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Val loss: 0.712985510006547, Acc:0.7386736703873933, F1-Macro: 0.5955736544034782\n",
      "Validation loss decreased 0.7388613211611906 - > 0.712985510006547\n",
      "Epoch 6, Train loss: 0.678066751697245, Acc:0.7517445201543387, F1-Macro: 0.6025094809162413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 7/20 [01:35<02:57, 13.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Val loss: 0.7181747819607457, Acc:0.7337491792514773, F1-Macro: 0.5899247223544847\n",
      "Early stopping counter 1/10\n",
      "Epoch 7, Train loss: 0.6484726528170228, Acc:0.7634020195386257, F1-Macro: 0.6115236961939304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 8/20 [01:49<02:43, 13.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Val loss: 0.7342343532169858, Acc:0.7301378857518056, F1-Macro: 0.5796328433190732\n",
      "Early stopping counter 2/10\n",
      "Epoch 8, Train loss: 0.6325665832035184, Acc:0.7711189557507594, F1-Macro: 0.6183679814746394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 9/20 [02:02<02:29, 13.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Val loss: 0.7091463586936394, Acc:0.7435981615233093, F1-Macro: 0.59651751781811\n",
      "Validation loss decreased 0.712985510006547 - > 0.7091463586936394\n",
      "Epoch 9, Train loss: 0.6292416716967355, Acc:0.7705442902881536, F1-Macro: 0.6189440132084688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 10/20 [02:16<02:15, 13.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Val loss: 0.6932106815899411, Acc:0.7531188443860801, F1-Macro: 0.6052176600638104\n",
      "Validation loss decreased 0.7091463586936394 - > 0.6932106815899411\n",
      "Epoch 10, Train loss: 0.6126158626999442, Acc:0.7762909449142107, F1-Macro: 0.6246104936590812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 11/20 [02:29<02:01, 13.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Val loss: 0.6729304976761341, Acc:0.7609980302035456, F1-Macro: 0.6104182648641363\n",
      "Validation loss decreased 0.6932106815899411 - > 0.6729304976761341\n",
      "Epoch 11, Train loss: 0.5997185035953372, Acc:0.7807240784828832, F1-Macro: 0.6272811830713397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 12/20 [02:43<01:47, 13.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Val loss: 0.6893165853495399, Acc:0.747866053841103, F1-Macro: 0.5974179460355438\n",
      "Early stopping counter 1/10\n",
      "Epoch 12, Train loss: 0.5907395635377078, Acc:0.7857318775141614, F1-Macro: 0.6336384018254048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 13/20 [02:56<01:34, 13.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, Val loss: 0.6822538975005349, Acc:0.7570584372948129, F1-Macro: 0.6062708353935459\n",
      "Early stopping counter 2/10\n",
      "Epoch 13, Train loss: 0.5703487320756662, Acc:0.7927920531976028, F1-Macro: 0.6414372189042272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 14/20 [03:10<01:20, 13.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, Val loss: 0.6810168915738662, Acc:0.7580433355219961, F1-Macro: 0.6107380054408618\n",
      "Early stopping counter 3/10\n",
      "Epoch 14, Train loss: 0.5477196632877109, Acc:0.796240045973237, F1-Macro: 0.6467599862473425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 15/20 [03:23<01:07, 13.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, Val loss: 0.6907382154216369, Acc:0.7541037426132633, F1-Macro: 0.6131787156183954\n",
      "Early stopping counter 4/10\n",
      "Epoch 15, Train loss: 0.5424555755193465, Acc:0.8039569821853707, F1-Macro: 0.6558008807389455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 16/20 [03:37<00:53, 13.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, Val loss: 0.7036121310666203, Acc:0.7580433355219961, F1-Macro: 0.6061423140970417\n",
      "Early stopping counter 5/10\n",
      "Epoch 16, Train loss: 0.5242615159884525, Acc:0.8066661193662261, F1-Macro: 0.6608876494440324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 17/20 [03:50<00:40, 13.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, Val loss: 0.7094305884093046, Acc:0.7560735390676296, F1-Macro: 0.6053327977516718\n",
      "Early stopping counter 6/10\n",
      "Epoch 17, Train loss: 0.5300345015259865, Acc:0.8039569821853707, F1-Macro: 0.6605007739600006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 18/20 [04:04<00:27, 13.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17, Val loss: 0.6816253044332067, Acc:0.7583716349310571, F1-Macro: 0.6071942300386772\n",
      "Early stopping counter 7/10\n",
      "Epoch 18, Train loss: 0.5058447112796187, Acc:0.8124948690583695, F1-Macro: 0.681008923192746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 19/20 [04:17<00:13, 13.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18, Val loss: 0.7148175472393632, Acc:0.7619829284307288, F1-Macro: 0.6174000456640542\n",
      "Early stopping counter 8/10\n",
      "Epoch 19, Train loss: 0.4807601214784963, Acc:0.8244807487070027, F1-Macro: 0.6950584675964901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [04:31<00:00, 13.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, Val loss: 0.7311292433490356, Acc:0.7508207485226527, F1-Macro: 0.6153676784203238\n",
      "Early stopping counter 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch_index in tqdm(range(EPOCHS)):\n",
    "    trainer.train_epoch(train_loader, epoch_index)\n",
    "    trainer.validate_epoch(val_loader, epoch_index)\n",
    "    \n",
    "    early_stopper.check_early_stopping(loss = trainer.val_mean_loss)\n",
    "    \n",
    "    if early_stopper.stop:\n",
    "        print('Early Stopped')\n",
    "        break\n",
    "    if early_stopper.save_model:\n",
    "        check_point = {\n",
    "            'model': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "        }\n",
    "        torch.save(check_point, os.path.join(result_dir,'best.pt'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9eb6c61d-cd7e-4e8e-9862-105b867eae00",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b5a8c4b0-a4fe-4db7-b960-54fb54a6a623",
   "metadata": {},
   "source": [
    "#### Define Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "293e2e97-cb8f-4086-a61f-4603737dadf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, datapath, normpath):\n",
    "        self.data_path = datapath\n",
    "        self.npy_list = os.listdir(self.data_path)\n",
    "        self.normparams = np.load(normpath).astype('float32')\n",
    "        self.mean = self.normparams[0]\n",
    "        self.std = self.normparams[1]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.npy_list)\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        filename = self.npy_list[index]\n",
    "        npypath = os.path.join(self.data_path, filename)\n",
    "        x = torch.from_numpy(np.load(npypath).astype('float32'))\n",
    "        x = (x-self.mean)/self.std\n",
    "        subx = x[-30*128:].reshape(1,-1)\n",
    "        return subx, filename"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "188a96bf-bf8e-4fcb-8eb9-fb271c2fe0ff",
   "metadata": {},
   "source": [
    "#### Set Dataset and Dataloader for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fdc91c71-b591-4685-be26-89045c613804",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = TestDataset(test_dir, norm_dir)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e94f7366-3e63-4fd4-9657-84a452566fc5",
   "metadata": {},
   "source": [
    "#### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "61f8ae3d-bcc7-41f5-9875-a8367f03ee26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAINED_MODEL_PATH = os.path.join(result_dir, 'best.pt')\n",
    "test_model = DOUBLE_CNN()\n",
    "test_model.load_state_dict(torch.load(TRAINED_MODEL_PATH)['model'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "78a7a0ff-07fe-4649-bbea-919856804318",
   "metadata": {},
   "source": [
    "#### Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ba1461ce-29cd-4f13-8904-a0d234830846",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "123it [00:02, 54.55it/s]\n"
     ]
    }
   ],
   "source": [
    "file_list = []\n",
    "pred_list = []\n",
    "\n",
    "test_model.to(DEVICE)\n",
    "test_model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch_index, (x,y) in tqdm(enumerate(test_loader)):\n",
    "        x = x.to(DEVICE)\n",
    "        pred = test_model(x)\n",
    "        \n",
    "        file_list.extend(list(y))\n",
    "        pred_list.extend(pred.argmax(dim=1).tolist())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c927b127-c8e9-4eab-ba99-57380b32f17f",
   "metadata": {},
   "source": [
    "#### Save predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f0d7bfc3-4240-4559-b2a9-461d425d10fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make dataframe of predictions\n",
    "results = pd.DataFrame({'rec_id':file_list, 'stage':pred_list})\n",
    "\n",
    "# Change predictions to labels\n",
    "label_decoding = {0:'W', 1:'N1', 2:'N2', 3:'N3', 4:'R'}\n",
    "results = results.replace(label_decoding)\n",
    "\n",
    "# Change order of predictios to match sample_submission.csv file\n",
    "sampledf = pd.read_csv(os.path.join(DATA_DIR,'sample_submission.csv'))\n",
    "sorter = list(sampledf['rec_id'])\n",
    "results = results.set_index('rec_id')\n",
    "results = results.loc[sorter].reset_index()\n",
    "\n",
    "# Save predictions\n",
    "results.to_csv(os.path.join(result_dir,'prediction.csv'),index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
